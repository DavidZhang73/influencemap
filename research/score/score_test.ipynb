{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import unidecode\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from research.data.data          import *\n",
    "from core.utils.entity_type      import Entity_type\n",
    "from core.search.query_paper_mag import paper_mag_multiquery\n",
    "from core.search.query_info      import paper_info_mag_check_multiquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data dataframe\n",
    "DATA_PATH = '~/influencemap/research/data/ccnr-science-careers-basic-stats.csv'\n",
    "data_df = get_q_data(DATA_PATH)\n",
    "#data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 2887\n"
     ]
    }
   ],
   "source": [
    "# Get author names and normalise\n",
    "author_names = data_df['AuthorName'].str.lower()\n",
    "author_names = author_names.str.replace('.', '')\n",
    "author_names = author_names.str.replace('\\'', '\\\\\\'')\n",
    "author_names = list(map(unidecode.unidecode, list(author_names)))\n",
    "random.shuffle(author_names)\n",
    "\n",
    "print(\"Number of authors:\", len(author_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n",
      "Number of authors: 98\n"
     ]
    }
   ],
   "source": [
    "# Get author ids\n",
    "name_maps = get_author_ids(author_names[0:100]) # For testing\n",
    "\n",
    "print(\"Number of authors:\", len(name_maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "# Generate paper mapping\n",
    "paper_map = dict()\n",
    "for name, author_ids in name_maps.items():\n",
    "    res_row = dict()\n",
    "    res_row['AuthorIds'] = author_ids\n",
    "    res_row['PaperIds']  = paper_mag_multiquery(Entity_type.AUTH, author_ids)\n",
    "    \n",
    "    paper_map[name] = res_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers 16512\n",
      "Total number of author ids 3935\n",
      "Average number of papers per name 168.48979591836735\n",
      "Average number of author ids per name 40.1530612244898\n"
     ]
    }
   ],
   "source": [
    "# Stats of paper mapping results\n",
    "paper_counter  = lambda x: len(x['PaperIds'])\n",
    "author_counter = lambda x: len(x['AuthorIds'])\n",
    "\n",
    "paper_count_per_name  = list(map(paper_counter, paper_map.values()))\n",
    "author_count_per_name = list(map(author_counter, paper_map.values()))\n",
    "\n",
    "print(\"Total number of papers\",\n",
    "      np.sum(paper_count_per_name))\n",
    "\n",
    "print(\"Total number of author ids\", \n",
    "      np.sum(author_count_per_name))\n",
    "\n",
    "print(\"Average number of papers per name\",\n",
    "      np.average(paper_count_per_name))\n",
    "\n",
    "print(\"Average number of author ids per name\",\n",
    "      np.average(author_count_per_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philip w anderson 388\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "hyatt m gibbs 20\n",
      "gary t horowitz 220\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "k m leung 177\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "lyle patrick 54\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "myron strongin 270\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 10\n",
      "To call API: 20\n",
      "david s cannell 148\n",
      "To call API: 20\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n"
     ]
    }
   ],
   "source": [
    "# Generate the paper information per author\n",
    "THREADS    = 8\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "import multiprocess\n",
    "from functools import reduce\n",
    "\n",
    "p = multiprocess.Pool(THREADS)\n",
    "\n",
    "paper_info_map = dict()\n",
    "for name, val_dict in paper_map.items():\n",
    "    papers = val_dict['PaperIds']\n",
    "\n",
    "    # Number of papers to process\n",
    "    print(name, len(papers))\n",
    "    \n",
    "    # Set up for threads\n",
    "    batches = (papers[i:i+BATCH_SIZE] for i in \\\n",
    "               range(0, len(papers), BATCH_SIZE))\n",
    "    batch_res = p.map(paper_info_mag_check_multiquery, batches)\n",
    "    paper_info_map[name] = reduce(lambda x, y: x + y, batch_res)\n",
    "\n",
    "    # Process in batches\n",
    "    #paper_info_map[name] = list()\n",
    "    #for batch in range(0, len(papers), BATCH_SIZE):\n",
    "    #     += paper_info_mag_check_multiquery(papers[batch:batch+BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for the scoring\n",
    "author_scores = dict()\n",
    "for name in paper_map.keys():\n",
    "    author_scores[name] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score authors - Total Q Score\n",
    "for name, paper_info_list in paper_info_map.items():\n",
    "    q_score = q_score_info_list(paper_info_list)\n",
    "    author_scores[name]['QScore'] = q_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

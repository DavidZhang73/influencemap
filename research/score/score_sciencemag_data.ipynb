{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import unidecode\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import copy\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from research.data.data          import *\n",
    "from research.data.utils         import *\n",
    "from research.score.scores       import *\n",
    "from research.score.filters      import *\n",
    "from core.utils.entity_type      import Entity_type\n",
    "from core.search.query_paper_mag import paper_mag_multiquery\n",
    "from core.search.query_info      import paper_info_mag_check_multiquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "YEAR_DIFF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data dataframe\n",
    "DATA_PATH = '~/influencemap/research/data/ccnr-science-careers-basic-stats.csv'\n",
    "data_df = get_q_data(DATA_PATH)\n",
    "data_df['AuthorDName'] = data_df['AuthorName']\n",
    "data_df['AuthorName']  = data_df['AuthorName'].apply(name_normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 2887\n"
     ]
    }
   ],
   "source": [
    "# Get author names and normalise\n",
    "author_names = data_df['AuthorDName'].str.lower()\n",
    "author_names = author_names.str.replace('.', '')\n",
    "author_names = author_names.str.replace('\\'', '\\\\\\'')\n",
    "author_names = list(map(unidecode.unidecode, list(author_names)))\n",
    "random.shuffle(author_names)\n",
    "\n",
    "print(\"Number of authors:\", len(author_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n",
      "Number of authors: 98\n"
     ]
    }
   ],
   "source": [
    "# Get author ids\n",
    "name_maps = get_author_ids(author_names[0:100]) # For testing\n",
    "\n",
    "print(\"Number of authors:\", len(name_maps.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "# Generate paper mapping\n",
    "paper_map = dict()\n",
    "for name, author_ids in name_maps.items():\n",
    "    res_row = dict()\n",
    "    res_row['AuthorIds'] = author_ids\n",
    "    res_row['PaperIds']  = paper_mag_multiquery(Entity_type.AUTH, author_ids)\n",
    "    \n",
    "    paper_map[name] = res_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers 16512\n",
      "Total number of author ids 3935\n",
      "Average number of papers per name 168.48979591836735\n",
      "Average number of author ids per name 40.1530612244898\n"
     ]
    }
   ],
   "source": [
    "# Stats of paper mapping results\n",
    "paper_counter  = lambda x: len(x['PaperIds'])\n",
    "author_counter = lambda x: len(x['AuthorIds'])\n",
    "\n",
    "paper_count_per_name  = list(map(paper_counter, paper_map.values()))\n",
    "author_count_per_name = list(map(author_counter, paper_map.values()))\n",
    "\n",
    "print(\"Total number of papers\",\n",
    "      np.sum(paper_count_per_name))\n",
    "\n",
    "print(\"Total number of author ids\", \n",
    "      np.sum(author_count_per_name))\n",
    "\n",
    "print(\"Average number of papers per name\",\n",
    "      np.average(paper_count_per_name))\n",
    "\n",
    "print(\"Average number of author ids per name\",\n",
    "      np.average(author_count_per_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "philip w anderson 388\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "hyatt m gibbs 20\n",
      "gary t horowitz 220\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "k m leung 177\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "lyle patrick 54\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "myron strongin 270\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 10\n",
      "To call API: 20\n",
      "david s cannell 148\n",
      "To call API: 20\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n",
      "To call API: 0\n"
     ]
    }
   ],
   "source": [
    "# Generate the paper information per author\n",
    "THREADS    = 8\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "import multiprocess\n",
    "from functools import reduce\n",
    "\n",
    "p = multiprocess.Pool(THREADS)\n",
    "\n",
    "paper_info_map = dict()\n",
    "for name, val_dict in paper_map.items():\n",
    "    papers = val_dict['PaperIds']\n",
    "\n",
    "    # Number of papers to process\n",
    "    print(name, len(papers))\n",
    "    \n",
    "    # Set up for threads\n",
    "    batches = (papers[i:i+BATCH_SIZE] for i in \\\n",
    "               range(0, len(papers), BATCH_SIZE))\n",
    "    batch_res = p.map(paper_info_mag_check_multiquery, batches)\n",
    "    paper_info_map[name] = reduce(lambda x, y: x + y, batch_res)\n",
    "\n",
    "    # Process in batches\n",
    "    #paper_info_map[name] = list()\n",
    "    #for batch in range(0, len(papers), BATCH_SIZE):\n",
    "    #     += paper_info_mag_check_multiquery(papers[batch:batch+BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save selected authors\n",
    "with open('selectedauthors', 'w') as f:\n",
    "    for author in author_names:\n",
    "        f.write(author + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for the scoring\n",
    "author_scores = dict()\n",
    "for name in paper_map.keys():\n",
    "    author_scores[name] = dict()\n",
    "    author_scores[name]['AuthorName'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score authors - Total Q Score\n",
    "for name, paper_info_list in paper_info_map.items():\n",
    "    filter_paper_info = filter_pub_year_diff(paper_info_list, diff = YEAR_DIFF)\n",
    "    q_score = q_score_paper_info_list(filter_paper_info)\n",
    "    author_scores[name]['QScore'] = q_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of topics 2014\n",
      "Average number of topics per author 34.214285714285715\n"
     ]
    }
   ],
   "source": [
    "# Generate n-hot topic/fos arrays for each of the paper informations\n",
    "\n",
    "topic_index = ['JournalName', 'ConferenceName']\n",
    "\n",
    "# Generate the total topics\n",
    "topics = set()\n",
    "for name, paper_info_list in paper_info_map.items():\n",
    "    for paper_info in paper_info_list:\n",
    "        for topic in topic_index:\n",
    "            if topic in paper_info:\n",
    "                # Just get first\n",
    "                topics.add(paper_info[topic])\n",
    "\n",
    "topic_vector = sorted(list(topics))\n",
    "\n",
    "name_topic_vector_map = dict()\n",
    "for name, paper_info_list in paper_info_map.items():\n",
    "    # Init topic vector\n",
    "    name_topic_vec = [0] * len(topic_vector)\n",
    "    for paper_info in paper_info_list:\n",
    "        for topic in topic_index:\n",
    "            if topic in paper_info:\n",
    "                # Just get first\n",
    "                name_topic_vec[topic_vector.index(paper_info[topic])] = 1\n",
    "\n",
    "    name_topic_vector_map[name] = name_topic_vec\n",
    "\n",
    "name_topic_vector_map\n",
    "print(\"Total number of topics\", len(topic_vector))\n",
    "print(\"Average number of topics per author\",\n",
    "      np.average(list(map(np.sum, name_topic_vector_map.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 19 98\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "Variance score: -0.20725191529773324\n"
     ]
    }
   ],
   "source": [
    "# Regression on topics above,\n",
    "x = list()\n",
    "y = list()\n",
    "train_authors = list(name_topic_vector_map.keys())\n",
    "random.shuffle(train_authors)\n",
    "for name in train_authors:\n",
    "    x.append(name_topic_vector_map[name])\n",
    "    y.append(author_scores[name]['QScore'])\n",
    "\n",
    "data_split = int(len(x) * 0.2)\n",
    "\n",
    "train_X = x[:-data_split]\n",
    "train_Y = y[:-data_split]\n",
    "test_X  = x[-data_split:]\n",
    "test_Y  = y[-data_split:]\n",
    "\n",
    "print(len(train_X), len(test_X), len(x))\n",
    "\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_X, train_Y)\n",
    "print(regr)\n",
    "\n",
    "print('Variance score:', regr.score(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12896"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate n-hot topic/fos arrays for each of the paper informations\n",
    "\n",
    "topic_index = 'FieldOfStudy'\n",
    "\n",
    "# Generate the total topics\n",
    "topics = set()\n",
    "for name, paper_info_list in paper_info_map.items():\n",
    "    for paper_info in paper_info_list:\n",
    "        if topic_index in paper_info:\n",
    "            # Just get first\n",
    "            for fos in paper_info[topic_index]:\n",
    "                topics.add(fos['FieldOfStudyName'])\n",
    "                #break\n",
    "\n",
    "topic_vector = sorted(list(topics))\n",
    "\n",
    "name_topic_vector_map = dict()\n",
    "for name, paper_info_list in paper_info_map.items():\n",
    "    # Init topic vector\n",
    "    name_topic_vec = [0] * len(topic_vector)\n",
    "    for paper_info in paper_info_list:\n",
    "        if topic_index in paper_info:\n",
    "            # Just get first\n",
    "            for fos in paper_info[topic_index]:\n",
    "                name_topic_vec[topic_vector.index(fos['FieldOfStudyName'])] = 1\n",
    "\n",
    "    name_topic_vector_map[name] = name_topic_vec\n",
    "\n",
    "name_topic_vector_map\n",
    "len(topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display author scores\n",
    "score_df = pd.DataFrame(list(author_scores.values()))\n",
    "#score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>None</td><td>QRank_x</td><td>QRank_y</td><td>CC10Rank</td></tr><tr><td>QRank_x</td><td>None</td><td>0.1845515426284187</td><td>0.18939399029273618</td></tr><tr><td>QRank_y</td><td>None</td><td>None</td><td>0.8197162671866048</td></tr><tr><td>CC10Rank</td><td>None</td><td>None</td><td>None</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>None</td><td>QRank_x</td><td>QRank_y</td><td>CC10Rank</td></tr><tr><td>QRank_x</td><td>None</td><td>0.2303465631543811</td><td>0.2550626309685696</td></tr><tr><td>QRank_y</td><td>None</td><td>None</td><td>0.9462583517457396</td></tr><tr><td>CC10Rank</td><td>None</td><td>None</td><td>None</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the q score rankings\n",
    "datascore_df = data_df[['AuthorName', 'QScore', 'CC10']]\n",
    "compare_df = pd.merge(score_df[score_df['QScore'] > 0],\n",
    "                      datascore_df, how='left', on='AuthorName')\n",
    "#compare_df = pd.merge(score_df, datascore_df, how='left', on='AuthorName')\n",
    "\n",
    "# Calculate ranks\n",
    "compare_df['QRank_x']  = compare_df['QScore_x'].rank()\n",
    "compare_df['QRank_y']  = compare_df['QScore_y'].rank()\n",
    "compare_df['CC10Rank'] = compare_df['CC10'].rank()\n",
    "\n",
    "ranks = [ 'QRank_x', 'QRank_y', 'CC10Rank' ]\n",
    "\n",
    "kendalltau_matrix = [[None for _ in range(len(ranks)+1)] \\\n",
    "                      for _ in range(len(ranks)+1)]\n",
    "for i, rank in enumerate(ranks):\n",
    "    kendalltau_matrix[0][i+1] = rank\n",
    "    kendalltau_matrix[i+1][0] = rank\n",
    "    \n",
    "spearmanr_matrix = copy.deepcopy(kendalltau_matrix)\n",
    "\n",
    "for x, y in itertools.combinations(ranks, 2):\n",
    "    kt = scipy.stats.kendalltau(compare_df[x], compare_df[y])\n",
    "    sr = scipy.stats.spearmanr(compare_df[x], compare_df[y])\n",
    "    kendalltau_matrix[ranks.index(x)+1][ranks.index(y)+1] = kt[0]\n",
    "    spearmanr_matrix[ranks.index(x)+1][ranks.index(y)+1]  = sr[0]\n",
    "\n",
    "\n",
    "display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) \\\n",
    "                                 for row in kendalltau_matrix)\n",
    "    )\n",
    "))\n",
    "\n",
    "display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) \\\n",
    "                                 for row in spearmanr_matrix)\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

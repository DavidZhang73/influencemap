{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the term frequency (reference venue) from a set of paper information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scipy.sparse    as sparse\n",
    "import numpy           as np\n",
    "\n",
    "from core.search.query_paper_mag import paper_mag_multiquery\n",
    "from core.search.query_info      import paper_info_mag_check_multiquery\n",
    "from core.utils.entity_type      import Entity_type\n",
    "\n",
    "from bag_of_venues import BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers for conference: 1386\n",
      "Complete cache entries found: 1386\n",
      "Partial cache entries found: 0\n",
      "No cache entries found: 0\n",
      "Total ids to query: 1386\n"
     ]
    }
   ],
   "source": [
    "# Conf id\n",
    "conf_id = 1127352206 #PLDI\n",
    "\n",
    "# Generate papers for the conference\n",
    "papers = paper_mag_multiquery(Entity_type.CONF, [conf_id])\n",
    "\n",
    "print(\"Papers for conference:\", len(papers))\n",
    "\n",
    "# Import paper information here!\n",
    "paper_informations = paper_info_mag_check_multiquery(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bov = BagOfWords()\n",
    "bov.fit(paper_informations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1 ... 0 0 0]\n",
      " [2 2 2 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "1186 1024\n",
      "28209\n"
     ]
    }
   ],
   "source": [
    "print(bov.tf_matrix.toarray())\n",
    "print(bov.title_dim, bov.venue_dim)\n",
    "print(np.sum(bov.tf_matrix.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "title1 = 'memsat checking axiomatic specifications of memory models'\n",
    "title2 = 'mechanized verification of fine grained concurrent programs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bov.title_to_vec(title1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36583339522585784"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bov.sim_titles(title1, title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 371,\n",
       "  'title': 'memsat checking axiomatic specifications of memory models',\n",
       "  'sim': 1.0000000000000002},\n",
       " {'idx': 126,\n",
       "  'title': 'synthesizing software verifiers from proof rules',\n",
       "  'sim': 0.7089306854261541},\n",
       " {'idx': 348,\n",
       "  'title': 'dynamic partial order reduction for relaxed memory models',\n",
       "  'sim': 0.7056422850727971},\n",
       " {'idx': 216,\n",
       "  'title': 'discovering properties about arrays in simple programs',\n",
       "  'sim': 0.6857254813237417},\n",
       " {'idx': 467,\n",
       "  'title': 'herding cats modelling simulation testing and data mining for weak memory',\n",
       "  'sim': 0.6754836711711946}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bov.most_sim(bov.title_to_vec(title1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 501,\n",
       "  'title': 'mechanized verification of fine grained concurrent programs',\n",
       "  'sim': 1.0},\n",
       " {'idx': 987,\n",
       "  'title': 'atomicity refinement for verified compilation',\n",
       "  'sim': 0.86350607762354},\n",
       " {'idx': 677,\n",
       "  'title': 'blame and coercion together again for the first time',\n",
       "  'sim': 0.8617274844321392},\n",
       " {'idx': 135,\n",
       "  'title': 'adoption and focus practical linear types for imperative programming',\n",
       "  'sim': 0.8251126821451},\n",
       " {'idx': 792,\n",
       "  'title': 'monadic abstract interpreters',\n",
       "  'sim': 0.8124444637023874}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bov.most_sim(bov.title_to_vec(title2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 16  1 ...  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "auth_vec = bov.author_to_vec('stephen m blackburn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 382,\n",
       "  'title': 'beltway getting around garbage collection gridlock',\n",
       "  'sim': 0.9458490602925756},\n",
       " {'idx': 149,\n",
       "  'title': 'immix a mark region garbage collector with space efficiency fast collection and mutator performance',\n",
       "  'sim': 0.93887134688203},\n",
       " {'idx': 447,\n",
       "  'title': 'the compressor concurrent incremental and parallel compaction',\n",
       "  'sim': 0.9235948757944468},\n",
       " {'idx': 444,\n",
       "  'title': 'free me a static analysis for automatic individual object reclamation',\n",
       "  'sim': 0.9039360825220187},\n",
       " {'idx': 683,\n",
       "  'title': 'z rays divide arrays and conquer speed and flexibility',\n",
       "  'sim': 0.896380999278975}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bov.most_sim(auth_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
